<?xml version='1.0'?>

<!-- Here comes the Extrae configuration.
     As a general rule, "enabled" means that the feature is enabled :)  If
     it's not enabled, then the value can be set to some default.
-->

<!-- Must we activate the tracing? Which is the tracing mode? (detail/burst) Where is it located? Which kind of trace? Version of the XML parser?-->
<trace enabled="yes"
 home="@sub_PREFIXDIR@"
 initial-mode="detail"
 type="paraver"
>

  <!-- Configuration of some MPI dependant values -->
  <mpi enabled="yes">
    <!-- Gather counters in the MPI routines? -->
    <counters enabled="yes" />
    <!-- Capture all MPI_Comm_* calls? -->
    <comm-calls enabled="yes" />
  </mpi>

  <!-- Emit information of the callstack -->
  <callers enabled="yes">
    <!-- At MPI calls, select depth level -->
    <mpi enabled="yes">1-3</mpi>
    <!-- At sampling points, select depth level -->
    <sampling enabled="yes">1-5</sampling>
  </callers>

  <!-- Configuration of some OpenMP dependant values -->
  <openmp enabled="yes" ompt="no">
    <!-- If the library instruments OpenMP, shall we gather info about locks?
         Obtaining such information can make the final trace quite large.
    -->
    <locks enabled="no" />
    <!-- Gather info about taskloops? -->
    <taskloop enabled="no" />
    <!-- Gather counters in the OpenMP routines? -->
    <counters enabled="yes" />
  </openmp>

  <!-- Configuration of some pthread dependant values -->
  <pthread enabled="no">
    <!-- If the library instruments pthread, shall we gather info about locks, mutexs and conds?
         Obtaining such information can make the final trace quite large.
    -->
    <locks enabled="no" />
    <!-- Gather counters in the pthread routines? -->
    <counters enabled="yes" />
  </pthread>

  <!-- Configuration of User Functions -->
  <user-functions enabled="yes" list="/home/bsc41/bsc41273/user-functions.dat" exclude-automatic-functions="no">
    <!-- Gather counters on the UF routines? -->
    <counters enabled="yes" />
  </user-functions>

  <!-- Configure which software/hardware counters must be collected -->
  <counters enabled="yes">
    <!-- Configure the CPU hardware counters. You can define here as many sets
         as you want. You can also define if MPI/OpenMP calls must report such
         counters.
         Starting-set property defines which set is chosen from every task.
         Possible values are:
           - cyclic : The sets are distributed in a cyclic fashion among all
           tasks. So Task 0 takes set 1, Task 1 takes set 2,...
           - block  : The sets are distributed in block fashion among all tasks.
           Task [0..i-1] takes set 1, Task [i..2*i-1] takes set 2, ...
           - Number : All the tasks will start with the given set 
           (from 1..N).
    -->
    <cpu enabled="yes" starting-set-distribution="1">
      <!-- In this example, we configure two sets of counters. The first will 
           be changed into the second after 5 calls to some collective
           operation on MPI_COMM_WORLD. Once the second is activated, it will
           turn to the first after 5seconds (aprox. depending on the MPI calls
           granularity)
           If you want that any set be counting forever, just don't set
           changeat-globalops, or, changeat-time.

           Each set has it's own properties.
           domain -> in which domain must PAPI obtain the information (see
                       PAPI info)
           changeat-globalops=num -> choose the next set after num
                       MPI_COMM_WORLD operations
           changeat-time=numTime -> choose the next set after num Time
                       (for example 5s, 15m (for ms), 10M (for minutes),..)
      -->
      <set enabled="yes" domain="all" changeat-globalops="5">
        PAPI_TOT_INS,PAPI_TOT_CYC,PAPI_L1_DCM
        <!-- Samples the application based on a frequency on a selected HWC  -->
        <sampling enabled="yes" frequency="100000000">PAPI_TOT_CYC</sampling>
      </set>
      <set enabled="yes" domain="user" changeat-globalops="5">
        PAPI_TOT_INS,PAPI_FP_INS,PAPI_TOT_CYC
      </set>
    </cpu>

    <!-- Do we want to gather information of the network counters?
         Nowadays we can gather information about MX/GM cards.
     -->
    <network enabled="no" />

    <!-- Obtain resource usage information -->
    <resource-usage enabled="no" />

    <!-- Obtain malloc statistics -->
    <memory-usage enabled="no" />
  </counters>

  <!-- Define the characteristics of the tracing storage. If not defined,
       or set, the tracing will send the traces to the current directory
       with a default output name.
  -->
  <storage enabled="no">
    <!-- The intermediate files will take the name of the application -->
    <trace-prefix enabled="yes">TRACE</trace-prefix>
    <!-- Stop the tracing when the intermediate file reaches this amount of MBs -->
    <size enabled="no">5</size>
    <!-- Where must we store the MPIT files while the app runs? -->
    <temporal-directory enabled="yes">/scratch</temporal-directory>
    <!-- Where must we store the MPIT files once the app ends? -->
    <final-directory enabled="yes">/gpfs/scratch/bsc41/bsc41273</final-directory>
  </storage>

  <!-- Buffer configuration -->
  <buffer enabled="yes">
    <!-- How many events can we handle before any flush -->
    <size enabled="yes">5000000</size>
    <!-- Use the event buffer in a circular manner? You can use this option to
         trace the last set of events. Needs MPI global routines operating on
         MPI_COMM_WORLD communicator to be merged
    -->
    <circular enabled="no" />
  </buffer>

  <!-- Control tracing -->
  <trace-control enabled="no">
    <!-- We can start the application with a "latent tracing" and wake it up
         once a control file is created. Use the property 'frequency' to
         choose at which frequency this check must be done. 
    -->
    <file enabled="no" frequency="5M">/gpfs/scratch/bsc41/bsc41273/control</file>
    <!-- Alternatively, you can specify a start[-end] range of collective operations
         over MPI_COMM_WORLD to start/stop the tracing.
    -->
    <global-ops enabled="no">50-100</global-ops>
  </trace-control>

  <!-- Other options -->
  <others enabled="no">
    <!-- Want to force a minimum amount of time of tracing? Here we force 10
         minutes -->
    <minimum-time enabled="no">10M</minimum-time>
  </others>

  <others enabled="yes">
    <minimum-time enabled="no">10M</minimum-time>
    <finalize-on-signal enabled="yes" 
      SIGUSR1="no" SIGUSR2="no" SIGINT="yes"
      SIGQUIT="yes" SIGTERM="yes" SIGXCPU="yes"
      SIGFPE="yes" SIGSEGV="yes" SIGABRT="yes"
    />
    <flush-sampling-buffer-at-instrumentation-point enabled="yes" />
  </others>

  <!-- Burst mode filters all tracing activity leaving only significant computations(ones that last longer than the defined threshold).  -->
  <!-- [mpi|omp]-statistics: reports the runtime activity as statistics. -->
  <!--  omp-summarization: Consider parallel regions as burst. And reporst statistics at entry and exit points -->
  <burst enabled="no" threshold="500u" mpi-statistics="yes" omp-statistics="yes" omp-summarization="no" />  <burst enabled="no" threshold="500u" mpi-statistics="yes" omp-statistics="yes" omp-summarization="no" />


  <!-- Enable sampling capabilities using system clock.
       Type may refer to: default, real, prof and virtual.
       Period stands for the sampling period (50ms here) 
       plus a variability of 10ms, which means periods from 
       45 to 55ms.
  -->
  <sampling enabled="no" type="default" period="50m" variability="10m" />

 <!-- Enable extra emission of the executing core id (Beware: High overhead!)
        options:
          frequency = Emit at instrumentation points only if enough time passed since last measurement
          emit-always = { yes, no } Emit even if core id has not changed since last measurement
          poi = { openmp } Emit at entry/exit of OpenMP outlined functions, tasks and work dispatches
  -->
  <cpu-events enabled="no" frequency="0" emit-always="no" poi="openmp" />


  <!-- Do merge the intermediate tracefiles into the final tracefile?
       options: 
       synchronization = { default, task, node, no } (default is node)
       binary = binary file to translate addresses into source code references
       max-memory = Number (in Mbytes) max memory used in merge step
       joint-states = { yes, no } generate joint states?
       keep-mpits = { yes, no } keep mpit files after merge?
  -->
  <merge enabled="yes" 
    synchronization="default"
    binary="mpi_ping"
    tree-fan-out="16"
    max-memory="512"
    joint-states="yes"
    keep-mpits="yes"
    translate-addresses="yes"
    sort-addresses="yes"
    translate-data-addresses="yes"
    overwrite="yes"
  >
    mpi_ping.prv 
  </merge>

</trace>
